{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36945892",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2299b",
   "metadata": {},
   "source": [
    "Environment closely follows OpenAI gym API. Currently can not be invoked with ```gym.make(\"env_id\")```, though it should be easy to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_go\n",
    "\n",
    "env = gym.make('gym_go:go-v0', size=BOARD_SIZE, komi=0, reward_method='real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monte_carlo_tree\n",
    "\n",
    "\n",
    "class GoNode(monte_carlo_tree.Node):\n",
    "    \"\"\"Go Game Tree Node\"\"\"\n",
    "\n",
    "    def prepare_state(self, player=None):\n",
    "        \"\"\"\n",
    "        Prepare game state X from perspective of current player\n",
    "        [\n",
    "            [ 1 -1 -1 ]\n",
    "            [ 1  0  0 ]\n",
    "            [ 0  0 -1 ]\n",
    "        ]\n",
    "\n",
    "        \n",
    "        Where  \n",
    "            1:  current player\n",
    "            -1: opposing player\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        if player == None:\n",
    "            player = self.current_player()\n",
    "\n",
    "        # take advantage of game symmetry        \n",
    "        state = self.blacks() - self.whites() if player == 1 else self.whites() - self.blacks()\n",
    "\n",
    "        return state\n",
    "\n",
    "    def whites(self):\n",
    "        \"\"\"White pieces on board\"\"\"\n",
    "        return self.state[0]\n",
    "    \n",
    "    def blacks(self):\n",
    "        \"\"\"Black pieces on board\"\"\"\n",
    "        return self.state[1]\n",
    "\n",
    "    def current_player(self):\n",
    "        return 1 if self.state[2, 0, 0] == 1 else -1\n",
    "    \n",
    "    def possible_actions(self):\n",
    "        \"\"\"List of possible next actions\"\"\"\n",
    "        actions = (self.blacks() + self.whites()) + self.state[3]\n",
    "\n",
    "        actions_ = np.zeros_like(actions)\n",
    "        actions_[actions==0] = 1\n",
    "        \n",
    "        return actions_\n",
    "\n",
    "    def possible_actions_list(self):\n",
    "        actions = self.possible_actions()\n",
    "        return np.argwhere(actions==1)\n",
    "\n",
    "    def prepare_action(self, action):\n",
    "        return action\n",
    "\n",
    "    def evaluate(self, env):\n",
    "        return env.winning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a7605",
   "metadata": {},
   "source": [
    "## Random Play Tree\n",
    "\n",
    "This is very basic algorithm that plays the game by making random moves. Sometimes it reaches the end goal, but overall it supper inneficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b968af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = monte_carlo_tree.RandomPlayTree(env, GoNode, BOARD_SIZE)\n",
    "\n",
    "\n",
    "def random_play():\n",
    "    '''\n",
    "    Play a game using random tree strategy\n",
    "    '''\n",
    "    return rt.simulate(rt.root_node)\n",
    "    \n",
    "\n",
    "def build_stats(playfunc, n_games=100):\n",
    "    '''\n",
    "    Play a number of random games and display result\n",
    "    '''\n",
    "\n",
    "    black_wins = 0\n",
    "    white_wins = 0\n",
    "    draws = 0\n",
    "    moves = []\n",
    "    \n",
    "    for _ in range(n_games):\n",
    "        m = playfunc()\n",
    "\n",
    "        reward = env.winning()\n",
    "\n",
    "        if reward > 0:\n",
    "            black_wins += 1\n",
    "        elif reward < 0:\n",
    "            white_wins += 1\n",
    "        elif reward == 0.0:\n",
    "            draws += 1\n",
    "       \n",
    "        moves.append(m.depth())\n",
    "    \n",
    "    print(\"Blacks: \", black_wins, \"Whites: \", white_wins, \"Draws: \", draws, \"Moves mean:\", np.mean(moves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e4494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_stats(random_play, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee835d",
   "metadata": {},
   "source": [
    "## Monte Carlo Search Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcst = monte_carlo_tree.MonteCarloPlayTree(env, GoNode, BOARD_SIZE)\n",
    "\n",
    "def mtsc_play():\n",
    "    '''\n",
    "    Play a game using MonteCarloSearchTree\n",
    "    '''\n",
    "    \n",
    "    return mcst.simulate(mcst.root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_stats(mtsc_play, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246da071",
   "metadata": {},
   "source": [
    "## Alpha Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, board_size=BOARD_SIZE):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.layer1 = nn.Linear(128, 64)\n",
    "        self.layer2 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = x.view(-1, 128)\n",
    "        \n",
    "        prob = torch.sigmoid(self.layer1(x))\n",
    "        value = torch.tanh(self.layer2(x))\n",
    "\n",
    "        return prob.view(-1, 8, 8), value.view(-1, 1)\n",
    "\n",
    "actor_critic_network = ActorCritic().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "azt = monte_carlo_tree.GuidedMonteCarloPlayTree(env, GoNode, BOARD_SIZE, actor_critic_network, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    for loss in azt.train(10):\n",
    "        losses.append(loss)\n",
    "    torch.save(actor_critic_network.state_dict(), \"./actor_critic.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156117f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
