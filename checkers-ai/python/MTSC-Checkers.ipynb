{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b6c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2299b",
   "metadata": {},
   "source": [
    "Environment closely follows OpenAI gym API. Currently can not be invoked with ```gym.make(\"env_id\")```, though it should be easy to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f4ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Env\n",
    "\n",
    "env = Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125c716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monte_carlo_tree\n",
    "\n",
    "def state_to_board(state):\n",
    "    board = np.zeros((3, 8, 8))\n",
    "    for piece in state['pieces']:\n",
    "        if piece['color'] == \"Black\":\n",
    "            board[0, piece['x'], piece['y']] = 1\n",
    "        else: \n",
    "            board[1, piece['x'], piece['y']] = 1\n",
    "        board[2] = 1 if state['turn']['color'] == \"Black\" else 0\n",
    "\n",
    "    return board\n",
    "\n",
    "\n",
    "class CheckersNode(monte_carlo_tree.Node):\n",
    "    \"\"\"Go Game Tree Node\"\"\"\n",
    "\n",
    "    def whites(self):\n",
    "        \"\"\"White pieces on board\"\"\"\n",
    "        return state_to_board(self.state)[1]\n",
    "    \n",
    "    def blacks(self):\n",
    "        \"\"\"Black pieces on board\"\"\"\n",
    "        return state_to_board(self.state)[0]\n",
    "\n",
    "    def get_piece_by_id(self, piece_id):\n",
    "        pieces = list(\n",
    "            filter(\n",
    "                lambda p: p['id'] == piece_id, \n",
    "                self.state['pieces']\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(pieces) > 0:\n",
    "            return pieces[0]\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_piece_by_coord(self, x, y):\n",
    "        pieces =  list(\n",
    "            filter(lambda p: p['x'] == x and p['y'] == y, \n",
    "                self.state['pieces']\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(pieces) > 0:\n",
    "            return pieces[0]\n",
    "\n",
    "        return None\n",
    "\n",
    "    def current_player(self):\n",
    "        \"\"\"Return 1 if current player plays black, and -1 for whites\"\"\"\n",
    "        return 1 if self.state['turn']['color'] == 'Black' else -1\n",
    "    \n",
    "    def possible_actions(self, player=None):\n",
    "        \"\"\"List of possible next actions\"\"\"\n",
    "        player = self.current_player()\n",
    "\n",
    "        coords = []\n",
    "        for piece_id in range(0, 24):\n",
    "            piece = self.get_piece_by_id(piece_id)\n",
    "\n",
    "            if piece is None: continue\n",
    "            if player == 0 and piece['color'] == \"Black\": continue\n",
    "            if player == 1 and piece['color'] == \"White\": continue\n",
    "                \n",
    "            for action in self.state['moveset'][piece_id]:\n",
    "                coords.append((piece['x'], piece['y'], action[0], action[1]))\n",
    "\n",
    "        actions = np.zeros((8, 8, 8, 8))\n",
    "        for c in coords: \n",
    "            actions[c] = 1\n",
    "        return actions\n",
    "\n",
    "    def possible_actions_list(self):\n",
    "        actions = self.possible_actions()\n",
    "        return np.argwhere(actions==1)\n",
    "\n",
    "    def evaluate(self, env):\n",
    "        return self.reward\n",
    "\n",
    "    def prepare_action(self, action):\n",
    "        return {\n",
    "            'piece': self.get_piece_by_coord(action[0], action[1]),\n",
    "            'square': {'x': int(action[2]), 'y': int(action[3])}\n",
    "        }\n",
    "    def prepare_state(self, player=None):\n",
    "        if player == None: player = self.current_player()  \n",
    "        state = self.blacks() - self.whites() if player == 1 else self.whites() - self.blacks()\n",
    "        if player == 1: state = np.flip(state, 1)\n",
    "        return state.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a7605",
   "metadata": {},
   "source": [
    "## Random Play Tree\n",
    "\n",
    "This is very basic algorithm that plays the game by making random moves. Sometimes it reaches the end goal, but overall it supper inneficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b968af",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_SIZE = 8\n",
    "\n",
    "rt = monte_carlo_tree.RandomPlayTree(env, CheckersNode, BOARD_SIZE)\n",
    "\n",
    "\n",
    "def random_play():\n",
    "    '''\n",
    "    Play a game using random tree strategy\n",
    "    '''\n",
    "    return rt.simulate(rt.root_node)\n",
    "    \n",
    "\n",
    "def build_stats(playfunc, n_games=100):\n",
    "    '''\n",
    "    Play a number of random games and display result\n",
    "    '''\n",
    "\n",
    "    black_wins = 0\n",
    "    white_wins = 0\n",
    "    draws = 0\n",
    "    moves = []\n",
    "    \n",
    "    for _ in range(n_games):\n",
    "        m = playfunc()\n",
    "\n",
    "        reward = m.reward\n",
    "\n",
    "        if reward > 0:\n",
    "            black_wins += 1\n",
    "        elif reward < 0:\n",
    "            white_wins += 1\n",
    "        elif reward == 0.0:\n",
    "            draws += 1\n",
    "       \n",
    "        moves.append(m.depth())\n",
    "    \n",
    "    print(\"Blacks: \", black_wins, \"Whites: \", white_wins, \"Draws: \", draws, \"Moves mean:\", np.mean(moves))\n",
    "    return (-black_wins + white_wins) / n_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9e4494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_stats(random_play, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee835d",
   "metadata": {},
   "source": [
    "## Monte Carlo Search Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9965a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcst = monte_carlo_tree.MonteCarloPlayTree(env, CheckersNode, BOARD_SIZE)\n",
    "\n",
    "def mtsc_play():\n",
    "    '''\n",
    "    Play a game using MonteCarloSearchTree\n",
    "    '''\n",
    "    \n",
    "    return mcst.simulate(mcst.root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeae88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_stats(mtsc_play, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246da071",
   "metadata": {},
   "source": [
    "## Alpha Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438b18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# class ActorCritic(nn.Module):\n",
    "\n",
    "#     def __init__(self, board_size=BOARD_SIZE):\n",
    "#         super(ActorCritic, self).__init__()\n",
    "        \n",
    "#         self.board_size = board_size\n",
    "#         self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.layer1 = nn.Linear(256, 4096)\n",
    "#         self.layer2 = nn.Linear(256, 1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "\n",
    "#         x = x.unsqueeze(1)\n",
    "\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = x.view(-1, 256)\n",
    "        \n",
    "#         prob = F.softmax(self.layer1(x), dim=0).view(-1, 8, 8, 8, 8)\n",
    "#         value = torch.tanh(self.layer2(x))\n",
    "\n",
    "#         return prob, value.view(-1, 1)\n",
    "\n",
    "# actor_critic_network = ActorCritic().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5f62f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, board_size=BOARD_SIZE):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.layer1 = nn.Linear(512, 4096)\n",
    "        self.layer2 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = x.view(-1, 512)\n",
    "        \n",
    "        prob = F.softmax(self.layer1(x), dim=0).view(-1, 8, 8, 8, 8)\n",
    "        value = F.hardtanh(self.layer2(x))\n",
    "\n",
    "        return prob, value.view(-1, 1)\n",
    "\n",
    "actor_critic_network = ActorCritic().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "284e757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "defa06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic_network.load_state_dict(torch.load(\"./checkers-big.pt\"))\n",
    "\n",
    "for i in range(0, 100):\n",
    "    alphazero_tree = monte_carlo_tree.GuidedMonteCarloPlayTree(env, CheckersNode, BOARD_SIZE, actor_critic_network, device)\n",
    "    for loss in alphazero_tree.train(100):\n",
    "        losses.append(loss)\n",
    "        torch.save(actor_critic_network.state_dict(), \"./checkers-big.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "plt.plot([l.detach().cpu().numpy() for l in losses])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7221dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
