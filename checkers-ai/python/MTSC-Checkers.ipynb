{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b6c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5f4ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Env\n",
    "\n",
    "env = Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "125c716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monte_carlo_tree\n",
    "\n",
    "def state_to_board(state):\n",
    "    board = np.zeros((3, 8, 8))\n",
    "    for piece in state['pieces']:\n",
    "        if piece['color'] == \"Black\":\n",
    "            board[0, piece['x'], piece['y']] = 1\n",
    "        else: \n",
    "            board[1, piece['x'], piece['y']] = 1\n",
    "        board[2] = 1 if state['turn']['color'] == \"Black\" else 0\n",
    "\n",
    "    return board\n",
    "\n",
    "\n",
    "class CheckersNode(monte_carlo_tree.Node):\n",
    "    \"\"\"Go Game Tree Node\"\"\"\n",
    "\n",
    "    def whites(self):\n",
    "        \"\"\"White pieces on board\"\"\"\n",
    "        return state_to_board(self.state)[1]\n",
    "    \n",
    "    def blacks(self):\n",
    "        \"\"\"Black pieces on board\"\"\"\n",
    "        return state_to_board(self.state)[0]\n",
    "\n",
    "    def get_piece_by_id(self, piece_id):\n",
    "        pieces = list(\n",
    "            filter(\n",
    "                lambda p: p['id'] == piece_id, \n",
    "                self.state['pieces']\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(pieces) > 0:\n",
    "            return pieces[0]\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_piece_by_coord(self, x, y):\n",
    "        pieces =  list(\n",
    "            filter(lambda p: p['x'] == x and p['y'] == y, \n",
    "                self.state['pieces']\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(pieces) > 0:\n",
    "            return pieces[0]\n",
    "\n",
    "        return None\n",
    "\n",
    "    def current_player(self):\n",
    "        \"\"\"Return 1 if current player plays black, and -1 for whites\"\"\"\n",
    "        return 1 if self.state['turn']['color'] == 'Black' else -1\n",
    "    \n",
    "    def possible_actions(self, player=None):\n",
    "        \"\"\"List of possible next actions\"\"\"\n",
    "        player = self.current_player()\n",
    "\n",
    "        coords = []\n",
    "        for piece_id in range(0, 24):\n",
    "            piece = self.get_piece_by_id(piece_id)\n",
    "\n",
    "            if piece is None: continue\n",
    "            if player == 0 and piece['color'] == \"Black\": continue\n",
    "            if player == 1 and piece['color'] == \"White\": continue\n",
    "                \n",
    "            for action in self.state['moveset'][piece_id]:\n",
    "                coords.append((piece['x'], piece['y'], action[0], action[1]))\n",
    "\n",
    "        actions = np.zeros((8, 8, 8, 8))\n",
    "        for c in coords: \n",
    "            actions[c] = 1\n",
    "        return actions\n",
    "\n",
    "    def possible_actions_list(self):\n",
    "        actions = self.possible_actions()\n",
    "        return np.argwhere(actions==1)\n",
    "\n",
    "    def evaluate(self, env):\n",
    "        return self.reward\n",
    "\n",
    "    def prepare_action(self, action):\n",
    "        return {\n",
    "            'piece': self.get_piece_by_coord(action[0], action[1]),\n",
    "            'square': {'x': int(action[2]), 'y': int(action[3])}\n",
    "        }\n",
    "    def prepare_state(self, player=None):\n",
    "        if player == None: player = self.current_player()  \n",
    "        state = self.blacks() - self.whites() if player == 1 else self.whites() - self.blacks()\n",
    "        if player == 1: state = np.flip(state, 1)\n",
    "        return state.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a7605",
   "metadata": {},
   "source": [
    "## Random Play Tree\n",
    "\n",
    "This is very basic algorithm that plays the game by making random moves. Sometimes it reaches the end goal, but overall it supper inneficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49b968af",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_SIZE = 8\n",
    "\n",
    "rt = monte_carlo_tree.RandomPlayTree(env, CheckersNode, BOARD_SIZE)\n",
    "\n",
    "\n",
    "def random_play():\n",
    "    '''\n",
    "    Play a game using random tree strategy\n",
    "    '''\n",
    "    return rt.simulate(rt.root_node)\n",
    "    \n",
    "\n",
    "def build_stats(playfunc, n_games=100):\n",
    "    '''\n",
    "    Play a number of random games and display result\n",
    "    '''\n",
    "\n",
    "    black_wins = 0\n",
    "    white_wins = 0\n",
    "    draws = 0\n",
    "    moves = []\n",
    "    \n",
    "    for _ in range(n_games):\n",
    "        m = playfunc()\n",
    "\n",
    "        reward = m.reward\n",
    "\n",
    "        if reward > 0:\n",
    "            black_wins += 1\n",
    "        elif reward < 0:\n",
    "            white_wins += 1\n",
    "        elif reward == 0.0:\n",
    "            draws += 1\n",
    "       \n",
    "        moves.append(m.depth())\n",
    "    \n",
    "    print(\"Blacks: \", black_wins, \"Whites: \", white_wins, \"Draws: \", draws, \"Moves mean:\", np.mean(moves))\n",
    "    return (-black_wins + white_wins) / n_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a9e4494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_stats(random_play, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee835d",
   "metadata": {},
   "source": [
    "## Monte Carlo Search Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9965a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcst = monte_carlo_tree.MonteCarloPlayTree(env, CheckersNode, BOARD_SIZE)\n",
    "\n",
    "def mtsc_play():\n",
    "    '''\n",
    "    Play a game using MonteCarloSearchTree\n",
    "    '''\n",
    "    \n",
    "    return mcst.simulate(mcst.root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeae88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_stats(mtsc_play, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246da071",
   "metadata": {},
   "source": [
    "## Alpha Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5f62f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, board_size=BOARD_SIZE):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.layer1 = nn.Linear(512, 4096)\n",
    "        self.layer2 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = x.view(-1, 512)\n",
    "        \n",
    "        prob = F.softmax(self.layer1(x), dim=0).view(-1, 8, 8, 8, 8)\n",
    "        value = F.hardtanh(self.layer2(x))\n",
    "\n",
    "        return prob, value.view(-1, 1)\n",
    "\n",
    "actor_critic_network = ActorCritic().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba9bff",
   "metadata": {},
   "source": [
    "Train a model for a few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defa06d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss total: tensor(177.3376, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(159.9630, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(37.6991, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(143.3092, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(286.8387, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(174.4517, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(51.5019, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(243.5333, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(126.0555, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(79.4810, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(140.0236, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(51.6170, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(104.1700, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(258.6516, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(57.6860, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(178.4077, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(202.0965, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(162.5177, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(44.2101, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(134.3576, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(59.1956, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(58.9690, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(50.4295, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(132.0028, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(79.0866, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(216.1960, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(96.8335, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(179.3871, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(48.3455, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(195.1869, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(40.5328, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(217.4285, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(182.1698, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(173.6331, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(248.1298, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(80.0872, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(50.1156, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(170.0156, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(74.7688, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(32.7476, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  -1\n",
      "Loss total: tensor(160.6428, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(173.7292, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(221.3637, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(106.5287, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(171.4065, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(103.8193, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(70.3318, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(235.1441, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(39.4869, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  -1\n",
      "Loss total: tensor(120.0708, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(167.8733, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(209.5263, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(218.8827, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(82.1707, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(240.7428, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(53.8949, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(69.3781, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(104.0016, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(225.1435, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(49.3531, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(179.8154, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(38.5160, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(191.6272, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(235.0769, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(189.5004, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(192.6707, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(44.2867, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  -1\n",
      "Loss total: tensor(37.7973, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  -1\n",
      "Loss total: tensor(205.9350, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(105.0363, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(38.7724, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(69.7095, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(40.1720, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  -1\n",
      "Loss total: tensor(75.7129, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(196.3486, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(67.7136, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(226.2140, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(204.1089, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(64.2879, device='cuda:0', grad_fn=<SumBackward0>) score:  0 player:  1\n",
      "Loss total: tensor(171.2725, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(209.3961, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(295.5831, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n",
      "Loss total: tensor(193.7765, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(207.0175, device='cuda:0', grad_fn=<SumBackward0>) score:  1 player:  1\n",
      "Loss total: tensor(205.2239, device='cuda:0', grad_fn=<SumBackward0>) score:  -1 player:  1\n"
     ]
    }
   ],
   "source": [
    "alphazero_tree = monte_carlo_tree.GuidedMonteCarloPlayTree(\n",
    "    env, \n",
    "    CheckersNode, \n",
    "    BOARD_SIZE, \n",
    "    actor_critic_network,\n",
    "    device,\n",
    ")\n",
    "\n",
    "alphazero_tree.train(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5178e2a",
   "metadata": {},
   "source": [
    "Wrap 2-headed actor-critic model to output only the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedActorCritic(ActorCritic):\n",
    "    \n",
    "    def __init__(self, ac):\n",
    "        super(WrappedActorCritic, self).__init__()\n",
    "        self.ac = ac\n",
    "\n",
    "    def forward(self, x):\n",
    "        a, _ = self.ac(x)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b27d69",
   "metadata": {},
   "source": [
    "Export model to ONNX format for Rust interop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2343582",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.from_numpy(alphazero_tree.root_node.prepare_state()).float().to(\"cpu\").unsqueeze(0)\n",
    "\n",
    "torch.onnx.export(\n",
    "    WrappedActorCritic(actor_critic_network).to(\"cpu\"), \n",
    "    example, \n",
    "    \"../../checkers-app/assets/model.onnx\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "82ea6adb180b12ed72836e614d5d57295654ca2a9780d621124b81b6a9baa809"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
